# ==================================================
# HAL Answering Service â€” Configuration
# ==================================================
# Windows:     copy .env.example .env
# Linux/macOS: cp .env.example .env
#
# Fill in the REQUIRED fields below, then run: python main.py
#
# DEMO MODE: If you just want to try it out, run: python main.py --demo
# Demo mode only needs LLM settings (below). It will prompt you on first run.
# SignalWire, PUBLIC_HOST, and OWNER_NAME are NOT needed for demo mode.

# --- SignalWire (REQUIRED for production, not needed for --demo) ---
# Get these from your SignalWire dashboard: https://signalwire.com
SIGNALWIRE_PROJECT_ID=your-project-id
SIGNALWIRE_TOKEN=your-api-token
SIGNALWIRE_SPACE=your-space-name
SIGNALWIRE_PHONE_NUMBER=+1XXXXXXXXXX

# --- Server (REQUIRED) ---
# Default: 127.0.0.1 (localhost only). Use 0.0.0.0 to listen on all interfaces
# (only needed behind a reverse proxy or if you know what you're doing).
HOST=127.0.0.1
PORT=8080
# Your public HTTPS hostname (from Tailscale Funnel, Cloudflare Tunnel, ngrok, etc.)
# Do NOT include https:// -- just the hostname, e.g. my-server.tailnet-abc.ts.net
PUBLIC_HOST=your-hostname.example.com

# --- Owner (REQUIRED) ---
# Name used in greetings: "You've reached {name}'s phone."
OWNER_NAME=YourName

# --- Hugging Face (optional but recommended) ---
# Needed if anonymous download fails or you hit rate limits while
# downloading the Chatterbox TTS model (~3 GB).
# Get a free token at: https://huggingface.co/settings/tokens
HF_TOKEN=

# --- Voice Cloning (optional) ---
# Device for Chatterbox TTS: auto, cuda, or cpu.
TTS_DEVICE=auto
# Optional local directory with pre-downloaded Chatterbox weights.
# If set (or if ./models/chatterbox exists), startup uses local files and skips HF download.
# Required files: ve.safetensors, t3_turbo_v1.safetensors, s3gen_meanflow.safetensors (+ tokenizer files).
# TTS_MODEL_DIR=models/chatterbox
# Path to a WAV file (>5 seconds) for voice cloning. Leave empty for default voice.
# Two sample voices are included: hal9000.wav and eugene.wav
TTS_VOICE_PROMPT=

# --- STT / Faster-Whisper (optional, defaults are fine) ---
STT_MODEL=large-v3-turbo
STT_DEVICE=auto
STT_COMPUTE_TYPE=auto
# Language hint (blank = auto-detect)
STT_LANGUAGE=en
# Decoding knobs
STT_BEAM_SIZE=1
STT_BEST_OF=1
STT_NO_SPEECH_THRESHOLD=0.6
STT_LOG_PROB_THRESHOLD=-1.0
STT_CONDITION_ON_PREVIOUS_TEXT=false
STT_INITIAL_PROMPT=Phone call screening conversation.
# Low-power suggestion:
# STT_MODEL=base
# STT_COMPUTE_TYPE=int8

# --- LLM ---
# Provider modes:
#   auto               -> inferred from LLM_BASE_URL (1234=LM Studio, 11434=Ollama)
#   lmstudio           -> LM Studio-specific request tuning
#   ollama             -> Ollama /v1 compatibility mode
#   openai_compatible  -> generic OpenAI-compatible server
LLM_PROVIDER=auto
# LM Studio default: http://127.0.0.1:1234/v1
# Ollama default:    http://127.0.0.1:11434/v1
LLM_BASE_URL=http://127.0.0.1:1234/v1
LLM_API_KEY=lm-studio
# For LM Studio you can leave blank to use server default.
# For Ollama set this explicitly (e.g. qwen3:4b).
LLM_MODEL=
LLM_MAX_TOKENS=200
LLM_TEMPERATURE=0.7
LLM_FREQUENCY_PENALTY=0.0

# --- VAD / Silero (optional, defaults are fine) ---
VAD_SPEECH_THRESHOLD=0.5
VAD_SILENCE_THRESHOLD_MS=400
VAD_MIN_SPEECH_MS=250

# --- Security (optional) ---
MAX_CONCURRENT_CALLS=3
MAX_CALL_DURATION_S=600
# Webhook signing key (falls back to SIGNALWIRE_TOKEN if unset)
# SIGNALWIRE_SIGNING_KEY=

# --- Recording & Metadata (optional) ---
RECORDINGS_DIR=recordings
# Call metadata (JSON) is stored separately from recordings for security.
# METADATA_DIR=metadata

# --- Notifications (optional) ---
# ntfy.sh topic for push notifications with call summaries.
# Create a free topic at https://ntfy.sh and put the topic name here.
# NTFY_TOPIC=
# Access token for authenticated ntfy topics (recommended).
# See https://docs.ntfy.sh/publish/#access-tokens
# NTFY_TOKEN=
