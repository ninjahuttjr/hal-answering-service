# ==================================================
# HAL Answering Service — Configuration
# ==================================================
# Quick start: just run `python main.py` — HAL will create a .env for you.
#
# For production: copy this file to .env and fill in the REQUIRED fields.
#   Windows:     copy .env.example .env
#   Linux/macOS: cp .env.example .env
#
# Demo mode (no phone line needed) only requires LLM settings below.
# SignalWire, PUBLIC_HOST, and OWNER_NAME are NOT needed for demo mode.

# --- SignalWire (REQUIRED for production, not needed for --demo) ---
# Get these from your SignalWire dashboard: https://signalwire.com
SIGNALWIRE_PROJECT_ID=your-project-id
SIGNALWIRE_TOKEN=your-api-token
SIGNALWIRE_SPACE=your-space-name
SIGNALWIRE_PHONE_NUMBER=+1XXXXXXXXXX

# --- Server (REQUIRED) ---
# Default: 127.0.0.1 (localhost only). Use 0.0.0.0 to listen on all interfaces
# (only needed behind a reverse proxy or if you know what you're doing).
HOST=127.0.0.1
PORT=8080
# Your public HTTPS hostname (from Tailscale Funnel, Cloudflare Tunnel, ngrok, etc.)
# Do NOT include https:// -- just the hostname, e.g. my-server.tailnet-abc.ts.net
PUBLIC_HOST=your-hostname.example.com

# --- Owner (REQUIRED) ---
# Name used in greetings: "You've reached {name}'s phone."
OWNER_NAME=YourName

# --- Voice (optional) ---
# Device for Chatterbox TTS: auto, cuda, or cpu.
TTS_DEVICE=auto
# Path to a WAV file (>5 seconds) for voice cloning.
# Defaults to hal9000.wav (included). Other sample: dwight.wav
TTS_VOICE_PROMPT=hal9000.wav
# Optional local directory with pre-downloaded Chatterbox weights.
# If set (or if ./models/chatterbox exists), startup uses local files and skips HF download.
# TTS_MODEL_DIR=models/chatterbox
# Hugging Face token — only needed if anonymous model download fails.
# Get a free token at: https://huggingface.co/settings/tokens
# HF_TOKEN=

# --- STT / Faster-Whisper (optional, defaults are fine) ---
STT_MODEL=large-v3-turbo
STT_DEVICE=auto
STT_COMPUTE_TYPE=auto
# Language hint (blank = auto-detect)
STT_LANGUAGE=en
# Decoding knobs
STT_BEAM_SIZE=1
STT_BEST_OF=1
STT_NO_SPEECH_THRESHOLD=0.6
STT_LOG_PROB_THRESHOLD=-1.0
STT_CONDITION_ON_PREVIOUS_TEXT=false
STT_INITIAL_PROMPT=Phone call screening conversation.
# Low-power suggestion:
# STT_MODEL=base
# STT_COMPUTE_TYPE=int8

# --- LLM ---
# Provider modes:
#   auto               -> inferred from LLM_BASE_URL (1234=LM Studio, 11434=Ollama)
#   lmstudio           -> LM Studio-specific request tuning
#   ollama             -> Ollama /v1 compatibility mode
#   openai_compatible  -> generic OpenAI-compatible server
LLM_PROVIDER=auto
# LM Studio default: http://127.0.0.1:1234/v1
# Ollama default:    http://127.0.0.1:11434/v1
LLM_BASE_URL=http://127.0.0.1:1234/v1
LLM_API_KEY=lm-studio
# For LM Studio you can leave blank to use server default.
# For Ollama set this explicitly (e.g. qwen3:4b).
LLM_MODEL=
LLM_MAX_TOKENS=200
LLM_TEMPERATURE=0.7
LLM_FREQUENCY_PENALTY=0.0

# --- VAD / Silero (optional, defaults are fine) ---
VAD_SPEECH_THRESHOLD=0.5
VAD_SILENCE_THRESHOLD_MS=400
VAD_MIN_SPEECH_MS=250

# --- Security (optional) ---
MAX_CONCURRENT_CALLS=3
MAX_CALL_DURATION_S=600
# Webhook signing key (falls back to SIGNALWIRE_TOKEN if unset)
# SIGNALWIRE_SIGNING_KEY=

# --- Recording & Metadata (optional) ---
RECORDINGS_DIR=recordings
# Call metadata (JSON) is stored separately from recordings for security.
# METADATA_DIR=metadata

# --- Notifications (optional) ---
# ntfy.sh topic for push notifications with call summaries.
# Create a free topic at https://ntfy.sh and put the topic name here.
# NTFY_TOPIC=
# Access token for authenticated ntfy topics (recommended).
# See https://docs.ntfy.sh/publish/#access-tokens
# NTFY_TOKEN=

